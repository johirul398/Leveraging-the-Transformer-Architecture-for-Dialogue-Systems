{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":2394486,"sourceType":"datasetVersion","datasetId":1447737},{"sourceId":6204084,"sourceType":"datasetVersion","datasetId":3562157},{"sourceId":6204140,"sourceType":"datasetVersion","datasetId":3562197}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(1234)\nAUTO = tf.data.experimental.AUTOTUNE\n!pip install tensorflow-datasets==1.2.0\nimport tensorflow_datasets as tfds\nimport re\nimport sys\nfrom time import time\nimport numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"id":"zB5-_RIWF5CR","execution":{"iopub.status.busy":"2023-08-01T12:14:47.092722Z","iopub.execute_input":"2023-08-01T12:14:47.093082Z","iopub.status.idle":"2023-08-01T12:15:12.376458Z","shell.execute_reply.started":"2023-08-01T12:14:47.093052Z","shell.execute_reply":"2023-08-01T12:15:12.375169Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"d1 = pd.read_json('/kaggle/input/covid-chitchat/9L_dataset.json')\nd1 = d1[:50000]\ndt = pd.read_csv('/kaggle/input/emphetic-dialog-fb/emotion-emotion_69k.csv')\nd = pd.read_csv('/kaggle/input/exemplary-empathy-2490/emotion_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:16:13.278909Z","iopub.execute_input":"2023-08-01T12:16:13.280080Z","iopub.status.idle":"2023-08-01T12:16:22.772857Z","shell.execute_reply.started":"2023-08-01T12:16:13.280034Z","shell.execute_reply":"2023-08-01T12:16:22.771671Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Concat data","metadata":{}},{"cell_type":"code","source":"concat_q = pd.concat([dt['Situation'], d['seeker_post'],d1['question']], ignore_index=True)\nconcat_q.dropna(inplace=True)\nprompt = concat_q.tolist()\n\nconcat_a = pd.concat([dt['labels'], d['response_post'], d1['answer']], ignore_index=True)\nconcat_a.dropna(inplace=True)\nresponse = concat_a.tolist()\n\nprint(len(prompt))\nprint(len(response))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:16:27.927224Z","iopub.execute_input":"2023-08-01T12:16:27.927626Z","iopub.status.idle":"2023-08-01T12:16:27.975268Z","shell.execute_reply.started":"2023-08-01T12:16:27.927594Z","shell.execute_reply":"2023-08-01T12:16:27.974296Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"max_len = 60\nmax_sample = 117125\nbatch_size = 64\nbuffer_size = 70000\nnumber_of_layer = 2\nd_model = 512\nnumber_of_head = 8\nunit = 128\ndropout = 0.1","metadata":{"id":"Rvt0lQ046q5j","execution":{"iopub.status.busy":"2023-08-01T12:16:31.857320Z","iopub.execute_input":"2023-08-01T12:16:31.857845Z","iopub.status.idle":"2023-08-01T12:16:31.863804Z","shell.execute_reply.started":"2023-08-01T12:16:31.857802Z","shell.execute_reply":"2023-08-01T12:16:31.862702Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preprocess","metadata":{}},{"cell_type":"code","source":"def text_preprocess(s):\n    s = s.lower().strip()\n    s= re.sub(r\"([?.!,])\", r\" \\1 \", s)\n    s = re.sub(r'[\" \"]+', \" \", s)\n    s = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", s)\n    s = s.strip()\n    return s\n\nprompt = [text_preprocess(s) for s in prompt]\nresponse = [text_preprocess(s) for s in response]","metadata":{"id":"RrNHfxbLI2J6","execution":{"iopub.status.busy":"2023-08-01T12:16:35.513496Z","iopub.execute_input":"2023-08-01T12:16:35.514201Z","iopub.status.idle":"2023-08-01T12:16:44.343725Z","shell.execute_reply.started":"2023-08-01T12:16:35.514165Z","shell.execute_reply":"2023-08-01T12:16:44.342672Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build Prompt and Response","metadata":{}},{"cell_type":"code","source":"tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(prompt + response, target_vocab_size=8000)\n\ns_token, e_token = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\nvocab_size = tokenizer.vocab_size + 2\n\nt_prompt, t_response = [], []\n\nfor (i, j) in zip(prompt, response):\n    i = s_token + tokenizer.encode(i) + e_token\n    j = s_token + tokenizer.encode(j) + e_token\n    if len(i) <= max_len and len(j) <= max_len:\n        t_prompt.append(i)\n        t_response.append(j)\n\nprompt = tf.keras.preprocessing.sequence.pad_sequences(t_prompt, maxlen=max_len, padding='post')\nresponse = tf.keras.preprocessing.sequence.pad_sequences(t_response, maxlen=max_len, padding='post')","metadata":{"id":"-tgwxA9H6q5o","execution":{"iopub.status.busy":"2023-08-01T12:16:48.750516Z","iopub.execute_input":"2023-08-01T12:16:48.751199Z","iopub.status.idle":"2023-08-01T12:19:12.976417Z","shell.execute_reply.started":"2023-08-01T12:16:48.751163Z","shell.execute_reply":"2023-08-01T12:19:12.975257Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Train and Validation Data","metadata":{}},{"cell_type":"code","source":"data = tf.data.Dataset.from_tensor_slices(({ 'inputs': prompt,'dec_inputs': response[:, :-1] },{'outputs': response[:, 1:]},))\ndata = data.cache()\ndata = data.shuffle(buffer_size)\ndata = data.batch(batch_size)\ndata = data.prefetch(tf.data.experimental.AUTOTUNE)\ndataset_size = len(data)\ntrain_size = int(0.8 * dataset_size)\ntrain_dataset = data.take(train_size)\nval_dataset = data.skip(train_size)","metadata":{"id":"uXT493ue6q5t","execution":{"iopub.status.busy":"2023-08-01T12:19:48.484825Z","iopub.execute_input":"2023-08-01T12:19:48.485234Z","iopub.status.idle":"2023-08-01T12:19:53.077615Z","shell.execute_reply.started":"2023-08-01T12:19:48.485190Z","shell.execute_reply":"2023-08-01T12:19:53.076214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Multi Head Attention","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n        super(MultiHeadAttention, self).__init__(name=name)\n        self.num_heads = num_heads\n        self.d_model = d_model\n        assert d_model % self.num_heads == 0\n        self.depth = d_model // self.num_heads\n\n        self.query_dense = tf.keras.layers.Dense(units=d_model)\n        self.key_dense = tf.keras.layers.Dense(units=d_model)\n        self.value_dense = tf.keras.layers.Dense(units=d_model)\n        self.dense = tf.keras.layers.Dense(units=d_model)\n\n    def get_config(self):\n        config = super(MultiHeadAttention,self).get_config()\n        config.update({ 'num_heads':self.num_heads,'d_model':self.d_model,})\n        return config\n\n    def split_heads(self, inputs, batch_size):\n        inputs = tf.keras.layers.Lambda(lambda inputs:tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth)))(inputs)\n        return tf.keras.layers.Lambda(lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3]))(inputs)\n\n    def call(self, inputs):\n        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n        batch_size = tf.shape(query)[0]\n   \n        query = self.query_dense(query)\n        key = self.key_dense(key)\n        value = self.value_dense(value)\n\n        query = self.split_heads(query, batch_size)\n        key = self.split_heads(key, batch_size)\n        value = self.split_heads(value, batch_size)\n        \n        # scaled_dot_product_attention   \n        matmul_qk = tf.matmul(query, key, transpose_b=True)\n        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n        logits = matmul_qk / tf.math.sqrt(depth)\n        if mask is not None:\n            logits += (mask * -1e9)\n        attention_weights = tf.nn.softmax(logits, axis=-1)\n        scaled_attention = tf.matmul(attention_weights, value)\n        #scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n        scaled_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.transpose(scaled_attention, perm=[0, 2, 1, 3]))(scaled_attention)\n\n        concat_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.reshape(scaled_attention,(batch_size, -1, self.d_model)))(scaled_attention)\n        outputs = self.dense(concat_attention)\n        return outputs","metadata":{"id":"esEx-cnc6q5x","execution":{"iopub.status.busy":"2023-08-01T12:20:30.061329Z","iopub.execute_input":"2023-08-01T12:20:30.061712Z","iopub.status.idle":"2023-08-01T12:20:30.076416Z","shell.execute_reply.started":"2023-08-01T12:20:30.061680Z","shell.execute_reply":"2023-08-01T12:20:30.075253Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Positional Encoding","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(tf.keras.layers.Layer):\n\n    def __init__(self, position, d_model):\n        super(PositionalEncoding, self).__init__()\n        self.pos_encoding = self.positional_encoding(position, d_model)\n\n    def get_config(self):\n        config = super(PositionalEncoding, self).get_config()\n        config.update({'position': self.position,'d_model': self.d_model,})\n        return config\n\n    def get_angles(self, position, i, d_model):\n        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n        return position * angles\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],d_model=d_model)\n        sines = tf.math.sin(angle_rads[:, 0::2])\n        cosines = tf.math.cos(angle_rads[:, 1::2])\n        pos_encoding = tf.concat([sines, cosines], axis=-1)\n        pos_encoding = pos_encoding[tf.newaxis, ...]\n        return tf.cast(pos_encoding, tf.float32)\n\n    def call(self, inputs):\n        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]","metadata":{"id":"gMxkf_4r6q5z","execution":{"iopub.status.busy":"2023-08-01T12:20:35.153958Z","iopub.execute_input":"2023-08-01T12:20:35.154363Z","iopub.status.idle":"2023-08-01T12:20:35.166961Z","shell.execute_reply.started":"2023-08-01T12:20:35.154331Z","shell.execute_reply":"2023-08-01T12:20:35.165768Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoder Blocks","metadata":{}},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({'query': inputs,'key': inputs,'value': inputs,'mask': padding_mask})\n    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n    add_attention = tf.keras.layers.add([inputs,attention])\n    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n\n    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n    add_attention = tf.keras.layers.add([attention,outputs])\n    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n\n    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n\n\n\n\ndef encoder(vocab_size,num_layers, units,d_model,num_heads,dropout, name=\"encoder\"):\n    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n    embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n    embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n\n    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n    for i in range(num_layers):\n        outputs = encoder_layer(units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,name=\"encoder_layer_{}\".format(i),)([outputs, padding_mask])\n\n    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"id":"CFjSwpDk6q50","execution":{"iopub.status.busy":"2023-08-01T12:20:40.293463Z","iopub.execute_input":"2023-08-01T12:20:40.294182Z","iopub.status.idle":"2023-08-01T12:20:40.308719Z","shell.execute_reply.started":"2023-08-01T12:20:40.294146Z","shell.execute_reply":"2023-08-01T12:20:40.307541Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Decoder Blocks","metadata":{}},{"cell_type":"code","source":"def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={'query': inputs,'key': inputs,'value': inputs,'mask': look_ahead_mask})\n    add_attention = tf.keras.layers.add([attention1,inputs])\n    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n\n    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={'query': attention1,'key': enc_outputs,'value': enc_outputs,'mask': padding_mask})\n    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n    add_attention = tf.keras.layers.add([attention2,attention1])\n    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n\n    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n    add_attention = tf.keras.layers.add([outputs,attention2])\n    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n\n    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],outputs=outputs,name=name)\n\n\n\n\ndef decoder(vocab_size, num_layers, units,d_model,num_heads,dropout,name='decoder'):\n    inputs = tf.keras.Input(shape=(None,), name='inputs')\n    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n    embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n    for i in range(num_layers):\n        outputs = decoder_layer(units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,name='decoder_layer_{}'.format(i),)(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],outputs=outputs,name=name)","metadata":{"id":"xK0TPLxG6q51","execution":{"iopub.status.busy":"2023-08-01T12:22:46.002515Z","iopub.execute_input":"2023-08-01T12:22:46.003205Z","iopub.status.idle":"2023-08-01T12:22:46.020744Z","shell.execute_reply.started":"2023-08-01T12:22:46.003168Z","shell.execute_reply":"2023-08-01T12:22:46.019551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Masking","metadata":{}},{"cell_type":"code","source":"class PaddingMaskLayer(tf.keras.layers.Layer):\n    def call(self, x):\n        mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n        return mask[:, tf.newaxis, tf.newaxis, :]\n    \n    \nclass LookAheadMaskLayer(tf.keras.layers.Layer):\n    def call(self, x):\n        seq_len = tf.shape(x)[1]\n        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n        padding_mask = PaddingMaskLayer()\n        padding_mask = padding_mask(x)\n        return tf.maximum(look_ahead_mask, padding_mask)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:22:50.649247Z","iopub.execute_input":"2023-08-01T12:22:50.649604Z","iopub.status.idle":"2023-08-01T12:22:50.658854Z","shell.execute_reply.started":"2023-08-01T12:22:50.649574Z","shell.execute_reply":"2023-08-01T12:22:50.657663Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformer","metadata":{}},{"cell_type":"code","source":"def transformer(vocab_size, num_layers,units, d_model,num_heads,dropout, name=\"transformer\"):\n    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n    \n    padding_mask_layer = PaddingMaskLayer()\n    enc_padding_mask = padding_mask_layer(inputs)\n    \n    mask_layer = LookAheadMaskLayer()\n    look_ahead_mask = mask_layer(dec_inputs)\n\n    d_mask_layer = PaddingMaskLayer()\n    dec_padding_mask = d_mask_layer(inputs)\n\n    enc_outputs = encoder(vocab_size=vocab_size,num_layers=num_layers,units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,)(inputs=[inputs, enc_padding_mask])\n\n    dec_outputs = decoder( vocab_size=vocab_size,num_layers=num_layers,units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:22:53.364791Z","iopub.execute_input":"2023-08-01T12:22:53.365148Z","iopub.status.idle":"2023-08-01T12:22:53.375200Z","shell.execute_reply.started":"2023-08-01T12:22:53.365117Z","shell.execute_reply":"2023-08-01T12:22:53.373694Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimizer and Loss ","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\naccuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:22:57.221422Z","iopub.execute_input":"2023-08-01T12:22:57.221858Z","iopub.status.idle":"2023-08-01T12:22:57.234836Z","shell.execute_reply.started":"2023-08-01T12:22:57.221814Z","shell.execute_reply":"2023-08-01T12:22:57.233833Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = transformer(vocab_size=vocab_size,num_layers=number_of_layer,units=unit,d_model=d_model,num_heads=number_of_head,dropout= 0.1)\n\nmodel.compile(optimizer=optimizer, loss=[loss], metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:23:04.682412Z","iopub.execute_input":"2023-08-01T12:23:04.683592Z","iopub.status.idle":"2023-08-01T12:23:07.473132Z","shell.execute_reply.started":"2023-08-01T12:23:04.683540Z","shell.execute_reply":"2023-08-01T12:23:07.472060Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"model.fit(train_dataset, epochs=60, validation_data = val_dataset)","metadata":{"id":"rgghPotR6q6C","outputId":"c4ab7806-3768-49bf-dc83-f21fb543bb49","execution":{"iopub.status.busy":"2023-08-01T12:23:23.383205Z","iopub.execute_input":"2023-08-01T12:23:23.383693Z","iopub.status.idle":"2023-08-01T15:18:29.073534Z","shell.execute_reply.started":"2023-08-01T12:23:23.383611Z","shell.execute_reply":"2023-08-01T15:18:29.072635Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Perplexity","metadata":{}},{"cell_type":"code","source":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\ntotal_loss = 0.0\nnum_batches = 0\nfor inputs, targets_dict in val_dataset:\n    targets = targets_dict['outputs']\n    predictions = model(inputs, training=False)\n    batch_loss = loss_object(targets, predictions)\n    average_batch_loss = tf.reduce_mean(batch_loss)\n    total_loss += average_batch_loss\n    num_batches += 1\naverage_loss = total_loss / num_batches\nperplexity = tf.exp(average_loss)\na = perplexity.numpy()\nprint(f\"Perplexity: {a}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:20:53.221870Z","iopub.execute_input":"2023-08-01T15:20:53.222274Z","iopub.status.idle":"2023-08-01T15:21:40.794693Z","shell.execute_reply.started":"2023-08-01T15:20:53.222240Z","shell.execute_reply":"2023-08-01T15:21:40.793697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"while True:\n    a = input(\"\\nInput: \")\n    if a == \"exit\":\n        break\n    s = text_preprocess(a)\n    s = tf.expand_dims(s_token + tokenizer.encode(s) + e_token, axis=0)\n    output = tf.expand_dims(s_token, 0)\n    for i in range(max_len):\n        predictions = model(inputs=[s, output], training=False)\n        predictions = predictions[:, -1:, :]\n        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n        if tf.equal(predicted_id, e_token[0]):\n            break\n        output = tf.concat([output, predicted_id], axis=-1)\n    \n    p = tf.squeeze(output, axis=0)\n    pre_prompt = tokenizer.decode([i for i in p if i < tokenizer.vocab_size])\n    print('Output: {}'.format(pre_prompt))\n  ","metadata":{"id":"q9wqUCGB6q6E","outputId":"2ef95545-6662-4f37-a99f-bdfe2f0cc28a","execution":{"iopub.status.busy":"2023-08-01T15:22:51.750249Z","iopub.execute_input":"2023-08-01T15:22:51.750603Z","iopub.status.idle":"2023-08-01T15:28:52.822461Z","shell.execute_reply.started":"2023-08-01T15:22:51.750574Z","shell.execute_reply":"2023-08-01T15:28:52.821369Z"},"trusted":true},"outputs":[],"execution_count":null}]}